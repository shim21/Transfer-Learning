{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <3장 : 고양이와 개 : 30줄의 케라스로 구현한 전이 학습>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 전이 학습 (Transfer Train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"미리학습된 공통적인 계층들은 활용하고, 특정 분류 작업에 적합한 계층들을 별도로 추가 및 제거하여 학습하는 방법\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적으로 새로운 분류기 모델을 만들기 위해 공통계층 뒤에 2~3개의 FC layer들을 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 미세 조정 (Fine Tune)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"사전 학습된 모델에서 하위계층의 가중치는 그대로 사용하고, 기존 작업과 관련된 상위 계층을 제거하고 새로운 계층으루 추가하여 훈련하는 것\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전이 학습과 미세 조정은 서로 교환적으로 사용되며, 전이 학습은 일반적인 개념으로 많이 사용되고, 미세 조정은 구현이라는 의미로 사용됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련할 데이터 셋이 많은 양을 보유한 경우, 모든 레이어에 대한 미세 조정을 수행하고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련할 데이터 셋의 양이 적을 경우, 마지막 몇 개의 레이어들에 대해서만 미세 조정을 수행함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 전이 학습과 케라스를 이용한 사용자 정의 분류기 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle에서 개와 고양이로 구성된 데이터셋 로드, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로드된 데이터셋을 Train_set과 Validation_set으로 분리하여 적절한 폴더에 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "리눅스의 경우 아래의 코드를 터미널에 입력하여 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "윈도우의 경우 다음 링크로 들어가 다운로드 진행 (윈도우는 다음과 같이 진행이 안됨)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n",
      "'unzip'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n",
      "'mv'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n",
      "지정된 경로를 찾을 수 없습니다.\n",
      "하위 디렉터리 또는 파일 train이(가) 이미 있습니다.\n",
      "다음 내용 진행 중 오류 발생: train.\n",
      "하위 디렉터리 또는 파일 val이(가) 이미 있습니다.\n",
      "다음 내용 진행 중 오류 발생: val.\n",
      "명령 구문이 올바르지 않습니다.\n",
      "명령 구문이 올바르지 않습니다.\n",
      "'ls'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n",
      "'ls'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n",
      "'ls'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n",
      "'ls'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/download/trani.zip\n",
    "!unzip train.zip\n",
    "!mv train data\n",
    "!cd data\n",
    "!mkdir train val\n",
    "!mkdir train/cat train/dog\n",
    "!mkdir val/cat val/dog\n",
    "!ls | grep cat | sort -R | head -250 | xargs -I my train/cat\n",
    "!ls | grep dog | sort -R | head -250 | xargs -I my train/dog\n",
    "!ls | grep cat | sort -R | head -250 | xargs -I my val/cat\n",
    "!ls | grep dog | sort -R | head -250 | xargs -I my val/dog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 파이프 라인 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet, preprocess_input\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_DIR = \"../sugo3/OneDrive/바탕 화면/Kaggle Dataset/cat and dog/train/\"\n",
    "VALIDATION_DATA_DIR = \"../sugo3/OneDrive/바탕 화면/Kaggle Dataset/cat and dog/val/\"\n",
    "TRAIN_SAMPLES = 500\n",
    "VALIDATION_SAMPLES = 500\n",
    "NUM_CLASSES = 2 # 분류할 클래스의 수\n",
    "IMG_WIDTH, IMG_HEIGHT = 224, 224 # 이미지 입력을 위한 이미지 크기 조정\n",
    "BATCH_SIZE = 64 # 학습에 사용할 데이터들의 배치 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function = preprocess_input, # 픽셀들의 정규롸를 위해 preprocess_input을 사용\n",
    "                                   rotation_range=20,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=-0.2,\n",
    "                                   zoom_range=0.2)\n",
    "val_datagen = ImageDataGenerator(preprocessing_function = preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20001 images belonging to 2 classes.\n",
      "Found 4999 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DATA_DIR,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=12345, # 난수 생성하기 위한 seed\n",
    "    class_mode = 'categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    VALIDATION_DATA_DIR,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=12345,\n",
    "    class_mode = 'categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_maker():\n",
    "    base_model = MobileNet(include_top=False, input_shape = (IMG_WIDTH, IMG_HEIGHT,3))\n",
    "    for layer in base_model.layers[:]:\n",
    "        layer.trainable = False # Freeze the layers\n",
    "    inputs = Input(shape=(IMG_WIDTH, IMG_HEIGHT,3))\n",
    "    custom_model = base_model(inputs)\n",
    "    custom_model = GlobalAveragePooling2D()(custom_model)\n",
    "    custom_model = Dense(64, activation = 'relu')(custom_model)\n",
    "    custom_model = Dropout(0.5)(custom_model)\n",
    "    predictions = Dense(NUM_CLASSES, activation = 'softmax')(custom_model)\n",
    "    return Model(inputs = inputs, outputs = predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 훈련\n",
    "1. 훈련 매개 변수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_maker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 12s 944ms/step - loss: 0.6388 - acc: 0.7039 - val_loss: 0.2210 - val_acc: 0.9570\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 7s 950ms/step - loss: 0.2827 - acc: 0.9092 - val_loss: 0.1126 - val_acc: 0.9648\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 7s 932ms/step - loss: 0.1991 - acc: 0.9343 - val_loss: 0.0712 - val_acc: 0.9824\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 7s 939ms/step - loss: 0.1454 - acc: 0.9560 - val_loss: 0.1017 - val_acc: 0.9629\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 7s 929ms/step - loss: 0.1728 - acc: 0.9495 - val_loss: 0.0646 - val_acc: 0.9766\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 7s 934ms/step - loss: 0.1788 - acc: 0.9396 - val_loss: 0.0650 - val_acc: 0.9707\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 7s 930ms/step - loss: 0.0809 - acc: 0.9815 - val_loss: 0.0845 - val_acc: 0.9707\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 7s 941ms/step - loss: 0.1632 - acc: 0.9330 - val_loss: 0.0863 - val_acc: 0.9688\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 7s 946ms/step - loss: 0.1935 - acc: 0.9073 - val_loss: 0.0680 - val_acc: 0.9727\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 7s 942ms/step - loss: 0.0919 - acc: 0.9664 - val_loss: 0.0781 - val_acc: 0.9727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21b0ca36040>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = 'binary_crossentropy',\n",
    "             optimizer = tf.keras.optimizers.Adam(lr=0.001),\n",
    "             metrics = ['acc'])\n",
    "model.fit_generator(train_generator,\n",
    "                   steps_per_epoch=math.ceil(float(TRAIN_SAMPLES)/BATCH_SIZE),\n",
    "                    epochs = 10,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=math.ceil(float(VALIDATION_SAMPLES)/BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
